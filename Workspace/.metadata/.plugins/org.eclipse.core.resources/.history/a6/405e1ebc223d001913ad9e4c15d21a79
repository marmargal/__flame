'''
Created on 9 feb. 2019

@author: inmam
'''
from Scraping.Frameworks import Soup

urlLefties = "https://www.lefties.com/es/#woman"





# for item in get_html.find_all(class_="sidemenu-list-item parent"):#, attrs="href"): ## ENLACES
#     print(item.get('a').get('href'))

def obtener_enlaces_Lefties(url):
    
    res = []
    get_html = Soup.get_html(url)

    for item in get_html.find_all("li", attrs={"class":"sidemenu-list-item parent"}):
        for a in item.find_all("a"):
            nombre = a.get_text()
            enlace = a.get('href')
            if(('/es/women/') in enlace):
                res.append(['WOMEN',nombre,enlace])
            if(('/es/men/') in enlace):
                res.append(['MEN',nombre,enlace])
            

    for i in res: print(i)
    return res;

def obtener_prendas(urlCategoria):
    
    res = []
    get_html = Soup.get_html(urlCategoria)
    
    for item in get_html.find_all(attrs={"a", "class":"grid-product-standard grid-product2"}): # sacamos la url de la prenda
        print (item.text)
        
    return res

###################################################################################################################################

# obtener_enlaces_Lefties(urlLefties)
obtener_prendas('https://www.lefties.com/es/women/last-trends/ne%C3%B3n-animal-c1030170005.html')
        

# for items in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".sidemenu-list-item"))):
#     link = items.find_element_by_css_selector(".reviewdata a")
#     link.click()
#     time.sleep(2)
# 
# get_html = BeautifulSoup(driver.page_source,"lxml")
# print(get_html)

# for item in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".sidemenu-list-item"))):
#     link = item.get_attribute("href")
#     link.click()
#     time.sleep(2)
#     
#     print(link)

#     name = item.find_element_by_css_selector("p a").text
#     review_title = item.find_element_by_css_selector("strong a[id^=ctl00_ctl00_ContentPlaceHolderFooter_ContentPlaceHolderBody_rptreviews]").text
#     review_data = ' '.join([' '.join(items.text.split()) for items in item.find_elements_by_css_selector(".reviewdata")])
#     print("Name: {}\nReview_Title: {}\nReview_Data: {}\n".format(name, review_title, review_data))

# driver.quit()